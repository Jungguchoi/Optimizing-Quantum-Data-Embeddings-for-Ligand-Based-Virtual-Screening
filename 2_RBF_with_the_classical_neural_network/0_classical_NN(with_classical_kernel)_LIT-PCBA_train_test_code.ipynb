{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6234573f-5589-44ab-b795-780a964bf694",
   "metadata": {},
   "source": [
    "## Application of the classical NN with the classical kernel function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83109747-b8f3-4351-b34f-e785016a5984",
   "metadata": {},
   "source": [
    "#### 0. Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d7c31c-b754-4c00-be53-004f9d2bf1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score as f1_score_calculation\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import data\n",
    "#import Embedding\n",
    "import Hybrid_nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba2e0fd-3da3-4da1-bc01-63c3b5fdf6a5",
   "metadata": {},
   "source": [
    "#### 1. Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a182f4d-07c5-4d98-b525-776a1fa0cefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'ALDH1'\n",
    "sampling = '1_6'\n",
    "feature_reduction = False\n",
    "classes = [0,1]\n",
    "\n",
    "quantum_embed = 'ZZ'\n",
    "n_qubits = 8\n",
    "kernel = 'RBF'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cb58b4-e35a-4e38-a12a-d7e0a3d23ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = data.data_load_and_process(dataset='protein', target=target, sampling=sampling, feature_reduction=feature_reduction, classes=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f13af3-67dc-4254-94b7-3dbd579166b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X_train:\",X_train.shape,\"/ X_test:\",X_test.shape,\"/Y_train:\",Y_train.shape,\"/Y_test:\",Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd21f0ec-bbed-441f-b5e2-f8321d8da90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Counter(Y_train), Counter(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106ee2fd-2ac4-4d6f-ba38-d576d1351203",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, X_test, Y_valid, Y_test = train_test_split(X_test, Y_test, test_size=0.5, shuffle=True,\n",
    "                                                            stratify=Y_test, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea5e470-be09-4a28-ab2e-a5209abd2bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"/ X_test:\",X_test.shape,\"/Y_valid:\",Y_valid.shape,\"/Y_test:\",Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d7ea03-6407-47ae-929e-ab0efa033208",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X_train:\",X_train.shape, \"/Y_train:\",Y_train.shape,\n",
    "      \"X_valid:\",X_valid.shape, \"/Y_test:\",Y_valid.shape,\n",
    "      \"X_test:\",X_test.shape,\"/Y_test:\",Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fce6a2f-74e2-49b2-8293-94b60e329f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.from_numpy(X_train).float()\n",
    "Y_train = torch.from_numpy(Y_train).long()\n",
    "X_valid = torch.from_numpy(X_valid).float()\n",
    "Y_valid = torch.from_numpy(Y_valid).long()\n",
    "X_test  = torch.from_numpy(X_test).float()\n",
    "Y_test  = torch.from_numpy(Y_test).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e796586b-589d-47cb-b6a5-fa88218da16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = '/Users/jungguchoi/Library/Mobile Documents/com~apple~CloudDocs/1_Post_doc(Cleveland_clinic:2024.10~2025.09)/1_Research_project/3_quantum_embedding_comparison_sequence(2024.09 ~ XXXX.XX)/2_exp/60_Dr_Park_Meeting_and_comments_SEP1725/2_new_classical_counterparts/15_ALDH1_NN_RBF_1_6_ratio/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378d415d-3f0f-4f31-9f30-6c276f91cbff",
   "metadata": {},
   "source": [
    "#### 2. Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2ffc03-46d9-43c5-a41e-5b113f7ce458",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopper:\n",
    "    def __init__(self, patience=40, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.min_validation_loss = np.inf\n",
    "\n",
    "    def early_stop(self, validation_loss):\n",
    "        if validation_loss < self.min_validation_loss:\n",
    "            self.min_validation_loss = validation_loss\n",
    "            self.counter = 0\n",
    "        elif validation_loss > (self.min_validation_loss + self.min_delta):\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa841032-c03c-463e-9092-993fd2d1cb38",
   "metadata": {},
   "source": [
    "#### 3. Main function for MLP training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8270c7-6e5d-4b43-a9ba-b8a185d6aa6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "iterations = 1000\n",
    "learning_rate = 0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0226755-e35a-4072-9849-4b11fdd5c8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(X_train, Y_train)\n",
    "valid_dataset = TensorDataset(X_valid, Y_valid)\n",
    "test_dataset = TensorDataset(X_test, Y_test)\n",
    "\n",
    "Train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=False)\n",
    "Valid_dataloader = DataLoader(valid_dataset, batch_size=int(X_valid.shape[0]), shuffle=True, drop_last=True)\n",
    "Test_dataloader = DataLoader(test_dataset, batch_size=int(X_test.shape[0]), shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba53435d-5ae8-46df-aee3-05bda5695478",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_calculation(proj_data, y):\n",
    "    n = proj_data.size(0)\n",
    "\n",
    "    # 1. RBF kernel\n",
    "    if kernel == 'RBF':\n",
    "        gamma = 1\n",
    "        squared_norms = (proj_data ** 2).sum(dim=1).unsqueeze(1)  # shape: (n, 1)\n",
    "        dists = squared_norms - 2 * proj_data @ proj_data.t() + squared_norms.t()\n",
    "        dists = torch.clamp(dists, min=0.0)\n",
    "        K = torch.exp(-gamma * dists)  # shape: (n, n)\n",
    "\n",
    "    # 2. Linear kernel\n",
    "    if kernel == 'Linear':\n",
    "        K = proj_data @ proj_data.t()\n",
    "    \n",
    "    y_flat = y.view(-1)  # shape: (n,)\n",
    "    labels = y_flat.unsqueeze(1) * y_flat.unsqueeze(0)  # shape: (n, n)\n",
    "    \n",
    "    loss_matrices = (K - 0.5 * (1 + labels)) ** 2\n",
    "    \n",
    "    tri_indices = torch.triu_indices(n, n, offset=1)\n",
    "    upper_elements = loss_matrices[tri_indices[0], tri_indices[1]]\n",
    "    \n",
    "    loss = upper_elements.mean()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d6e42f-751c-4e74-9b8f-f41ac7038ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(model_name, batch_size, learning_rate):\n",
    "    train_loss, valid_loss = [], []\n",
    "    model = Hybrid_nn.get_model(model_name)\n",
    "    model.train()\n",
    "    early_stopper = EarlyStopper(patience=40, min_delta=0)\n",
    "    early_stopped, final_it = False, 0\n",
    "\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    for it in range(iterations):\n",
    "        for train_inputs, train_targets in Train_dataloader:\n",
    "            train_proj_data = model(train_inputs)\n",
    "\n",
    "            loss_training = loss_calculation(train_proj_data, train_targets)\n",
    "            \n",
    "            opt.zero_grad()\n",
    "            loss_training.backward()\n",
    "            opt.step()\n",
    "            \n",
    "        train_loss.append(loss_training.item())\n",
    "        \n",
    "        if it % 10 == 0:\n",
    "            print(\"-------------------------------------\")\n",
    "            print(f\"Iterations: {it} Training Loss: {loss_training.item()}\")\n",
    "            with torch.no_grad():\n",
    "                \n",
    "                for valid_inputs, valid_targets in Valid_dataloader:\n",
    "                    valid_proj_data = model(valid_inputs)\n",
    "                    loss_validation = loss_calculation(valid_proj_data, valid_targets)\n",
    "                    print(f\"Validation Loss: {loss_validation}\")\n",
    "                    valid_loss.append(loss_validation.item())\n",
    "\n",
    "                    if early_stopper.early_stop(loss_validation):\n",
    "                        print(\"Loss converged!\")\n",
    "                        early_stopped = True\n",
    "                        final_it = it\n",
    "                        break\n",
    "\n",
    "                if early_stopped:\n",
    "                    break\n",
    "        if early_stopped:\n",
    "            break \n",
    "\n",
    "    with torch.no_grad():\n",
    "        for test_inputs, test_targets in Test_dataloader:\n",
    "            test_proj_data = model(test_inputs)\n",
    "            loss_test = loss_calculation(test_proj_data, test_targets)\n",
    "            print(f\"Test Loss: {loss_test}\")\n",
    "            \n",
    "    f = open(f\"{save_dir}/{model_name}_LIT-PCBA_{str(target)}_{str(sampling)}_sampling_MLP_{quantum_embed}_{str(n_qubits)}_qubits({kernel}).txt\", 'w')\n",
    "    f.write(\"Loss History:\\n\")\n",
    "    f.write(str(train_loss))\n",
    "    f.write(\"\\n\\n\")\n",
    "    f.write(\"Validation Loss History:\\n\")\n",
    "    f.write(str(valid_loss))\n",
    "    f.write(\"\\n\")\n",
    "    f.write(\"\\n\\n\")\n",
    "    f.write(f\"Test Loss: {loss_test}\\n\")\n",
    "    if early_stopped == True:\n",
    "        f.write(f\"Validation Loss converged. Early Stopped at iterations {final_it}\")\n",
    "    f.close()\n",
    "    torch.save(model.state_dict(), f'{save_dir}/{model_name}_LIT-PCBA_{str(target)}_{str(sampling)}_sampling_MLP_{quantum_embed}_{str(n_qubits)}_qubits({kernel}).pt')\n",
    "\n",
    "    return train_loss, valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bd5947-cb40-47e3-a98c-f2b28e88046e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_name = 'MLP1'\n",
    "train_loss, valid_loss = train_models(model_name, batch_size, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f53e9bf-c1fe-4600-a39c-ef9a8355b7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7794d5f3-6e88-4ddc-aae8-3c469014a9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(valid_loss)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
